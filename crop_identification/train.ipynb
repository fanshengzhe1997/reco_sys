{"cells":[{"cell_type":"markdown","metadata":{"id":"Zj2ZOHPESIpk"},"source":["# Author imformation:\n","Fan Shengzhe, Shanghaijiaotong University, Shanghai, China  \n","Email: fanshengzhe@sjtu.edu.cn"]},{"cell_type":"markdown","metadata":{"id":"42YwrUyBLFFK"},"source":["# Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"giJRjtNXlvzt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667531234906,"user_tz":-480,"elapsed":25943,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"}},"outputId":"ba6c6d3e-778e-456a-d234-a9cb7d9d403f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjyrbukLl1U5"},"outputs":[],"source":["import os\n","os.chdir(\"drive/My Drive/crop_identification2/crop_identification\")"]},{"cell_type":"markdown","metadata":{"id":"FbNiqB8bLT22"},"source":["# Install suitable tensorflow version\n","Notice: This script is based on tensorflow 2.x, and tensorflow 1.x will not be supported."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTWyF0nJpNsX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667531238785,"user_tz":-480,"elapsed":3886,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"}},"outputId":"2c1338da-17cd-4d0a-8bc5-4801625d644f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.2\n"]}],"source":["import tensorflow as tf \n","print(tf.__version__)\n","# if tf.__version__ != '2.8.2':\n","#   !pip install tensorflow==2.8.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVkPE2zqjLpJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667531241854,"user_tz":-480,"elapsed":22,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"}},"outputId":"f9ffc11e-a675-4218-8501-61564fcc4614"},"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 18366238995071460134\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14415560704\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 4137842114555822142\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiEY3k85FcX0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667531246746,"user_tz":-480,"elapsed":4910,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"}},"outputId":"09866a17-79e6-4825-e8cd-e9ae8ff8aaa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 30.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.18.0\n"]}],"source":["try:\n","  import tensorflow_addons\n","except:\n","  !pip install tensorflow_addons"]},{"cell_type":"markdown","metadata":{"id":"VONxCceEsXtB"},"source":["# copy data to temporary folder\n","\n","copy the data to the temporary folder in colab instead read the data from google drive may solve the problem which is extremely slow in the first epoch click the following URL for details: https://discuss.pytorch.org/t/drastically-slow-speed-at-first-epoch/12551/9\n","\n","copying folder may be slow, zip the folder may solve this porblem \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qxfPqjvF17z"},"outputs":[],"source":["if not (os.path.exists('/content/data.rar') or os.path.exists('/content/data')):\n","  !cp data.rar /content/ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqFm4gXxuLRB"},"outputs":[],"source":["if not os.path.exists('/content/data'):\n","  !unrar x -inul /content/data.rar /content\n","  !rm -rf /content/data.rar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2Yyzzkr3JAL"},"outputs":[],"source":["DATA_ROOT_PATH = '/content/data'"]},{"cell_type":"markdown","metadata":{"id":"ngO-V31JMg6W"},"source":["# Import necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lglrSqSLmXRI"},"outputs":[],"source":["import tensorflow as tf\n","import itertools\n","import datetime\n","import time\n","import json\n","import math\n","import io\n","from matplotlib import pyplot as plt\n","from functools import partial\n","from model_builder import *\n","from config import *\n","from utils import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGt0enuR0kNy"},"outputs":[],"source":["MODEL_NAME = 'ghost_efficientnet_v2_s'\n","BATCH_SIZE = 32"]},{"cell_type":"markdown","metadata":{"id":"-5IB_dEJMm8D"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBqPumV_mj2Z","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1b9e1c36-7581-49f2-c582-616ab1cc8b3a","executionInfo":{"status":"error","timestamp":1667570621863,"user_tz":-480,"elapsed":6740204,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: class_dict found and reused\n","INFO: ckpt found, restarted from epoch 6\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  7\n","train \t loss: 1.4579751 \t metrics: 0.60475755 \t lr: 0.00039810716\n","val \t loss: 1.1901783 \t metrics: 0.6746927 \t current_best_epoch: 7\n","Time taken for epoch 7 is 2884.9259119033813 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  8\n","train \t loss: 1.3352083 \t metrics: 0.63476807 \t lr: 0.00035481344\n","val \t loss: 1.1565617 \t metrics: 0.68457735 \t current_best_epoch: 8\n","Time taken for epoch 8 is 2820.6662123203278 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  9\n","train \t loss: 1.2261584 \t metrics: 0.6616741 \t lr: 0.0003162278\n","val \t loss: 1.040364 \t metrics: 0.71245724 \t current_best_epoch: 9\n","Time taken for epoch 9 is 2819.1916043758392 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  10\n","train \t loss: 1.1321907 \t metrics: 0.68413025 \t lr: 0.0002818383\n","val \t loss: 1.0054262 \t metrics: 0.7227221 \t current_best_epoch: 10\n","Time taken for epoch 10 is 2814.441075563431 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  11\n","train \t loss: 1.0466408 \t metrics: 0.7051998 \t lr: 0.00025118864\n","val \t loss: 0.9908624 \t metrics: 0.7304524 \t current_best_epoch: 11\n","Time taken for epoch 11 is 2819.2562119960785 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  12\n","train \t loss: 0.980871 \t metrics: 0.7211157 \t lr: 0.00022387214\n","val \t loss: 0.915027 \t metrics: 0.7442656 \t current_best_epoch: 12\n","Time taken for epoch 12 is 2820.5038483142853 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  13\n","train \t loss: 0.918429 \t metrics: 0.7367005 \t lr: 0.00019952626\n","val \t loss: 0.89148396 \t metrics: 0.7554176 \t current_best_epoch: 13\n","Time taken for epoch 13 is 2820.701432466507 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  14\n","train \t loss: 0.8609362 \t metrics: 0.7520507 \t lr: 0.00017782795\n","val \t loss: 0.8490905 \t metrics: 0.75921935 \t current_best_epoch: 14\n","Time taken for epoch 14 is 2821.2507421970367 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  15\n","train \t loss: 0.8086552 \t metrics: 0.7665317 \t lr: 0.00015848932\n","val \t loss: 0.8568739 \t metrics: 0.76378155 \t current_best_epoch: 15\n","Time taken for epoch 15 is 2814.415612220764 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  16\n","train \t loss: 0.7634744 \t metrics: 0.7778598 \t lr: 0.00014125377\n","val \t loss: 0.802349 \t metrics: 0.7803827 \t current_best_epoch: 16\n","Time taken for epoch 16 is 2818.8955533504486 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  17\n","train \t loss: 0.72206914 \t metrics: 0.78940177 \t lr: 0.00012589258\n","val \t loss: 0.831792 \t metrics: 0.7674566 \t current_best_epoch: 16\n","Time taken for epoch 17 is 2818.6475582122803 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  18\n","train \t loss: 0.6944492 \t metrics: 0.7959903 \t lr: 0.000112201866\n","val \t loss: 0.8070021 \t metrics: 0.7789887 \t current_best_epoch: 16\n","Time taken for epoch 18 is 2821.180422782898 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  19\n","train \t loss: 0.6636769 \t metrics: 0.80381376 \t lr: 0.00010000001\n","val \t loss: 0.7887748 \t metrics: 0.7849449 \t current_best_epoch: 19\n","Time taken for epoch 19 is 2823.0590586662292 sec\n","\n","--------------------------------------------------------------------------------\n","ghost_efficientnet_v2_s \t Epoch  20\n","train \t loss: 0.80511874 \t metrics: 0.81318474 \t lr: 9.1456415e-05"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-e718ea7c1cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m                           datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-e718ea7c1cdf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_ds, total_epochs, val_ds)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmetrics_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, current_epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mtrain_total_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["@tf.function\n","def train_step(input_img, label):\n","    with tf.GradientTape() as tape:\n","        pred = model(input_img, training=True)\n","        loss = loss_obj(label, pred)\n","\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer_obj.apply_gradients(zip(gradients, model.trainable_variables))\n","    metrics_obj.update_state(label, pred)\n","    return loss\n","\n","@tf.function\n","def test_step(input_img, label):\n","    pred = model(input_img, training=False)\n","    loss = loss_obj(label, pred)\n","    metrics_obj.update_state(label, pred)\n","    return loss\n","\n","\n","def fit(train_ds, total_epochs, val_ds=None):\n","    current_epoch = 0\n","    best_metrics = 0\n","    best_epoch = 0\n","\n","    # load ckpt here\n","    if os.path.exists(os.path.join(DAILY_CHECKPOINT_DIR, MODEL_NAME)):\n","        daily_ckpt.restore(tf.train.latest_checkpoint(os.path.join(DAILY_CHECKPOINT_DIR, MODEL_NAME)))\n","        print(f'INFO: ckpt found, restarted from epoch {epoch_recoder.numpy()}')\n","        print('-' * 80)\n","        current_epoch = epoch_recoder.numpy() + 1\n","        best_metrics = metrics_recoder.numpy()\n","        best_epoch = best_epoch_recoder.numpy()\n","    else:\n","        print('INFO: No ckpt found, start new training...')\n","        print('-' * 80)\n","    for _ in itertools.count():\n","        start_time = time.time()\n","        print(MODEL_NAME, '\\t', \"Epoch \", current_epoch)\n","\n","        train_total_loss = 0\n","        batch_num = 1\n","        metrics_obj.reset_states()\n","        for n, (input_img, label) in train_ds.enumerate():\n","            loss = train_step(input_img, label)#, current_epoch)\n","            train_total_loss += loss\n","            batch_num = n + 1\n","            print('\\rtrain', '\\t', 'loss:', loss.numpy(), '\\t', \n","                'metrics:', metrics_obj.result().numpy(), '\\t',\n","                'lr:', lr_schedule(optimizer_obj.iterations).numpy(), end='')\n","        metrics = metrics_obj.result()\n","        train_total_loss /= tf.cast(batch_num, tf.float32)\n","        with summary_writer.as_default():\n","            tf.summary.scalar('train_loss', train_total_loss, step=current_epoch)\n","            tf.summary.scalar('train_metrics', metrics, step=current_epoch)\n","            tf.summary.scalar('lr', lr_schedule(optimizer_obj.iterations),step=current_epoch)\n","        print('\\rtrain', '\\t', 'loss:', train_total_loss.numpy(), '\\t', \n","            'metrics:', metrics.numpy(), '\\t',\n","            'lr:', lr_schedule(optimizer_obj.iterations).numpy())\n","\n","        if val_ds is not None:\n","            val_total_loss = 0\n","            batch_num = 1\n","            metrics_obj.reset_states()\n","            for n, (input_img, label) in val_ds.enumerate():\n","                loss = test_step(input_img, label) #, current_epoch)\n","                val_total_loss += loss\n","                batch_num = n + 1\n","                print('\\rval', '\\t', 'loss:', loss.numpy(), '\\t',\n","                  'metrics:', metrics_obj.result().numpy(), end='')\n","            val_total_loss /= tf.cast(batch_num, tf.float32)\n","            metrics = metrics_obj.result()\n","\n","            if metrics > best_metrics:\n","                best_metrics = metrics\n","                best_epoch = current_epoch\n","                metrics_recoder.assign(best_metrics)\n","                epoch_recoder.assign(current_epoch)\n","                best_epoch_recoder.assign(best_epoch)\n","                best_ckpt_manager.save(checkpoint_number=best_epoch)\n","\n","            with summary_writer.as_default():\n","                tf.summary.scalar('val_loss', val_total_loss, step=current_epoch)\n","                tf.summary.scalar('val_metrics', metrics, step=current_epoch)\n","            print('\\rval', '\\t', 'loss:', val_total_loss.numpy(), '\\t',\n","               'metrics:', metrics.numpy(), '\\t',\n","               'current_best_epoch:', best_epoch)\n","\n","\n","        if (current_epoch + 1) % 1 == 0:\n","            # save the model every epoches\n","            epoch_recoder.assign(current_epoch)\n","            daily_ckpt_manager.save(checkpoint_number=current_epoch)\n","        end_time = time.time()\n","        print('Time taken for epoch {} is {} sec\\n'.format(current_epoch, end_time - start_time))\n","        print('-' * 80)\n","        with summary_writer.as_default():\n","            tf.summary.scalar('time taken', end_time - start_time, step=current_epoch)\n","\n","        current_epoch += 1\n","        if current_epoch >= EPOCHS:\n","            print('training done')\n","            break\n","\n","    # save the model when all epochs have been done\n","    daily_ckpt_manager.save(checkpoint_number=EPOCHS)\n","\n","\n","if __name__ == \"__main__\":\n","    # Creat class dict\n","    if not os.path.exists(os.path.join(CLASS_DICT_DIR, \"class_dict.json\")):\n","      if not os.path.exists(CLASS_DICT_DIR):\n","        os.mkdir(CLASS_DICT_DIR)\n","      cls_dict, rev_cls_dict = make_class_dict(DATA_ROOT_PATH, TRAIN_DIR_NAME, TEST_DIR_NAME, VAL_DIR_NAME)\n","      with open(f\"{CLASS_DICT_DIR}/class_dict.json\", \"w\") as jfile:\n","        json.dump((cls_dict, rev_cls_dict), jfile)\n","      print(\"WARN: no class_dict found, created new one. The model must be trained from scratch\")\n","    else:\n","      jfile = open(f\"{CLASS_DICT_DIR}/class_dict.json\", \"r\")\n","      cls_dict, rev_cls_dict = json.load(jfile)\n","      print(\"INFO: class_dict found and reused\")\n","    \n","    # Define model\n","    model = get_model(MODEL_NAME, IMAGE_H, IMAGE_W, 3, len(cls_dict))\n","    # Plot NN Arch\n","    # model.build((100, IMAGE_H, IMAGE_W, 3))\n","    # model.summary()\n","    # tf.keras.utils.plot_model(model)\n","\n","    # Creat data pipeline\n","    train_image_path_list, train_label = get_img_path_list(DATA_ROOT_PATH, TRAIN_DIR_NAME, class_dict=cls_dict, one_hot=True)\n","    train_dataset = tf.data.Dataset.from_tensor_slices((train_image_path_list, train_label))\n","    train_dataset = train_dataset.shuffle(buffer_size=100)\n","    tsfm_train = partial(transform_train, height=IMAGE_H, width=IMAGE_W)\n","    train_dataset = train_dataset.map(tsfm_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    train_dataset = train_dataset.batch(BATCH_SIZE)\n","    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    val_image_path_list, val_label = get_img_path_list(DATA_ROOT_PATH, VAL_DIR_NAME, class_dict=cls_dict, one_hot=True)\n","    val_dataset = tf.data.Dataset.from_tensor_slices((val_image_path_list, val_label))\n","    tsfm_val = partial(transform_test, height=IMAGE_H, width=IMAGE_W)\n","    val_dataset = val_dataset.map(tsfm_val, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    val_dataset = val_dataset.batch(BATCH_SIZE)\n","    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    \n","    \n","    # Show example\n","    # for inp, label in train_dataset.take(10):\n","    #     plt.imshow(inp[0] * 0.5 + 0.5)\n","    #     plt.title(rev_cls_dict[int(tf.argmax(label[0], axis=0).numpy())])\n","    #     plt.axis('off')\n","    #     plt.tight_layout()\n","    #     plt.show()\n","    \n","    # Loss, metrices, lr schedule and optimizer\n","    loss_obj = tf.keras.losses.CategoricalCrossentropy()\n","    metrics_obj = tf.keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_categorical_accuracy')\n","    steps_per_epoch = math.ceil(len(train_image_path_list)/BATCH_SIZE)\n","    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(LEARNING_RATE, decay_steps=20*steps_per_epoch, decay_rate=0.1)\n","    # lr_schedule = tf.keras.experimental.CosineDecay(LEARNING_RATE, DECAY_STEPS, alpha=0.01)\n","    # DECAY_STEPS = 2*steps_per_epoch\n","    # lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(LEARNING_RATE, first_decay_steps=DECAY_STEPS, \\\n","    #                                   t_mul=2.0, m_mul=0.75, alpha=0.001)\n","\n","    optimizer_obj = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n","\n","    # Recoder and checkpoints\n","    epoch_recoder = tf.Variable(0)\n","    metrics_recoder = tf.Variable(0.)\n","    best_epoch_recoder = tf.Variable(0)\n","\n","    daily_ckpt = tf.train.Checkpoint(optimizer=optimizer_obj,\n","                      model=model,\n","                      current_epoch=epoch_recoder,\n","                      current_best_metrics=metrics_recoder,\n","                      current_best_epoch=best_epoch_recoder)\n","    daily_ckpt_manager = tf.train.CheckpointManager(daily_ckpt, os.path.join(DAILY_CHECKPOINT_DIR, MODEL_NAME), 3)\n","\n","    best_ckpt = tf.train.Checkpoint(optimizer=optimizer_obj,\n","                      model=model,\n","                      current_epoch=epoch_recoder,\n","                      current_best_metrics=metrics_recoder,\n","                      current_best_epoch=best_epoch_recoder)\n","    best_ckpt_manager = tf.train.CheckpointManager(best_ckpt, os.path.join(BEST_CHECKPOINT_DIR, MODEL_NAME), 3)\n","\n","    # Tensorboard summary\n","    summary_writer = \\\n","    tf.summary.create_file_writer(os.path.join(LOG_DIR, MODEL_NAME, f\"bs{BATCH_SIZE}_lr{LEARNING_RATE}_ds{DECAY_STEPS}\",\n","                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n","    # Training\n","    fit(train_dataset, EPOCHS, val_dataset)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1655531331264}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}