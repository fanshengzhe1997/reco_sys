{"cells":[{"cell_type":"markdown","metadata":{"id":"Zj2ZOHPESIpk"},"source":["# Author imformation:\n","Fan Shengzhe, Shanghaijiaotong University, Shanghai, China  \n","Email: fanshengzhe@sjtu.edu.cn"]},{"cell_type":"markdown","metadata":{"id":"42YwrUyBLFFK"},"source":["# Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4471,"status":"ok","timestamp":1667317171298,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"},"user_tz":-480},"id":"giJRjtNXlvzt","outputId":"3f6d7c73-5d3a-4908-c733-1fd4416e78f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjyrbukLl1U5"},"outputs":[],"source":["import os\n","os.chdir(\"drive/My Drive/crop_identification2/crop_identification\")"]},{"cell_type":"markdown","metadata":{"id":"FbNiqB8bLT22"},"source":["# Install suitable tensorflow version\n","Notice: This script is based on tensorflow 2.x, and tensorflow 1.x will not be supported."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2770,"status":"ok","timestamp":1667317174063,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"},"user_tz":-480},"id":"bTWyF0nJpNsX","outputId":"c78b6e63-6640-4382-a034-4fb48a2882a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.9.2\n"]}],"source":["import tensorflow as tf \n","print(tf.__version__)\n","# if tf.__version__ != '2.8.2':\n","#   !pip install tensorflow==2.8.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1667317174837,"user":{"displayName":"Shengzhe Fan","userId":"13086747944144427617"},"user_tz":-480},"id":"sVkPE2zqjLpJ","outputId":"ba6683fc-d66d-4dd4-f0ee-4df016905e2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 3202661005756027316\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14415560704\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 136644900925538041\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}],"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiEY3k85FcX0"},"outputs":[],"source":["try:\n","  import tensorflow_addons\n","except:\n","  !pip install tensorflow_addons"]},{"cell_type":"markdown","metadata":{"id":"VONxCceEsXtB"},"source":["# copy data to temporary folder\n","\n","copy the data to the temporary folder in colab instead read the data from google drive may solve the problem which is extremely slow in the first epoch click the following URL for details: https://discuss.pytorch.org/t/drastically-slow-speed-at-first-epoch/12551/9\n","\n","copying folder may be slow, zip the folder may solve this porblem \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qxfPqjvF17z"},"outputs":[],"source":["if not (os.path.exists('/content/data.rar') or os.path.exists('/content/data')):\n","  !cp data.rar /content/ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqFm4gXxuLRB"},"outputs":[],"source":["if not os.path.exists('/content/data'):\n","  !unrar x -inul /content/data.rar /content\n","  !rm -rf /content/data.rar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2Yyzzkr3JAL"},"outputs":[],"source":["DATA_ROOT_PATH = '/content/data'"]},{"cell_type":"markdown","metadata":{"id":"ngO-V31JMg6W"},"source":["# Import necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lglrSqSLmXRI"},"outputs":[],"source":["import tensorflow as tf\n","import itertools\n","import datetime\n","import time\n","import json\n","import math\n","import io\n","from matplotlib import pyplot as plt\n","from functools import partial\n","from model_builder import *\n","from config import *\n","from utils import *\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGt0enuR0kNy"},"outputs":[],"source":["BATCH_SIZE = 16"]},{"cell_type":"markdown","metadata":{"id":"-5IB_dEJMm8D"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UBqPumV_mj2Z","outputId":"53982eed-25f4-47b8-d600-1120da753ddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: class_dict found and reused\n","model: se_resnext_101\n","loss: top1_metrics: top3_metrics: top5_metrics: top10_metrics: rwma_metrics: time_taken(s): sample_num speed(iter/s)\n"," 1.9173 0.5203 0.7159 0.792 0.8742 0.6333 201.9888 7891 39.0665\n"]}],"source":["@tf.function\n","def test_step(input_img, label):\n","    pred = model(input_img, training=False)\n","    loss = loss_obj(label, pred)\n","    top1_metrics_obj.update_state(label, pred)\n","    top3_metrics_obj.update_state(label, pred)\n","    top5_metrics_obj.update_state(label, pred)\n","    top10_metrics_obj.update_state(label, pred)\n","    return loss\n","\n","if __name__ == \"__main__\":\n","    # Creat class dict\n","    if not os.path.exists(os.path.join(CLASS_DICT_DIR, \"class_dict.json\")):\n","      raise Exception(\"class dict not found\") \n","    else:\n","      with open(f\"{CLASS_DICT_DIR}/class_dict.json\", \"r\") as jfile:\n","          cls_dict, rev_cls_dict = json.load(jfile)\n","      print(\"INFO: class_dict found and reused\")\n","\n","    # All models\n","    # vanilla_cnn = ['vanilla_cnn']\n","    # ghost_efficientnet_v2 = ['ghost_efficientnet_v2_s', 'ghost_efficientnet_v2_m', 'ghost_efficientnet_v2_l', 'ghost_efficientnet_v2_xl']\n","    # efficientnet_v2 = ['efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'efficientnet_v2_xl']\n","    # mobilenet_v3 = ['mobilenet_v3_small', 'mobilenet_v3_large']\n","    # se_resnext = ['se_resnext_50', 'se_resnext_101']\n","\n","    model_name = 'se_resnext_101'\n","    # Define model\n","    model = get_model(model_name, IMAGE_H, IMAGE_W, 3, len(cls_dict))\n","    \n","    # Data pipeline\n","    test_image_path_list, test_label = get_img_path_list(DATA_ROOT_PATH, TEST_DIR_NAME, class_dict=cls_dict, one_hot=True)\n","    test_dataset = tf.data.Dataset.from_tensor_slices((test_image_path_list, test_label))\n","    tsfm_test = partial(transform_test, height=IMAGE_H, width=IMAGE_W)\n","    test_dataset = test_dataset.map(tsfm_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    test_dataset = test_dataset.batch(BATCH_SIZE)\n","    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    # Loss, metrices\n","    loss_obj = tf.keras.losses.CategoricalCrossentropy()\n","    top1_metrics_obj = tf.keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_categorical_accuracy')\n","    top3_metrics_obj = tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_categorical_accuracy')\n","    top5_metrics_obj = tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_categorical_accuracy')\n","    top10_metrics_obj = tf.keras.metrics.TopKCategoricalAccuracy(k=10, name='top_10_categorical_accuracy')\n","    \n","    # Define ckpt\n","    best_ckpt = tf.train.Checkpoint(model=model)\n","\n","    # Load ckpt\n","    if not os.path.exists(os.path.join(BEST_CHECKPOINT_DIR, model_name)):\n","      raise Exception(\"ckpt not found\")\n","    else:\n","      best_ckpt.restore(tf.train.latest_checkpoint(os.path.join(BEST_CHECKPOINT_DIR, model_name))).expect_partial()\n","\n","    test_total_loss = 0\n","    batch_num = 1\n","    top1_metrics_obj.reset_states()\n","    top3_metrics_obj.reset_states()\n","    top5_metrics_obj.reset_states()\n","    top10_metrics_obj.reset_states()\n","    starttime = time.time()\n","    print('model:', model_name)\n","    print('loss:', 'top1_metrics:', 'top3_metrics:', 'top5_metrics:', \n","        'top10_metrics:', 'rwma_metrics:', 'time_taken(s):', \n","        'sample_num', 'speed(iter/s)',)\n","    for n, (input_img, label) in test_dataset.enumerate():\n","        loss = test_step(input_img, label)\n","        test_total_loss += loss\n","        batch_num = n + 1\n","        print('\\rtesting', \n","          round(loss.numpy(), 4),\n","          round(top1_metrics_obj.result().numpy(), 4),\n","          round(top3_metrics_obj.result().numpy(), 4),\n","          round(top5_metrics_obj.result().numpy(), 4),\n","          round(top10_metrics_obj.result().numpy(), 4),\n","          round((10*top1_metrics_obj.result().numpy()+\n","            5*top3_metrics_obj.result().numpy()+\n","            3*top5_metrics_obj.result().numpy()+\n","            1*top10_metrics_obj.result().numpy())/19, 4),\n","          end='')\n","    endtime = time.time()\n","\n","    test_total_loss /= tf.cast(batch_num, tf.float32)\n","    top1_metrics = top1_metrics_obj.result()\n","    top3_metrics = top3_metrics_obj.result()\n","    top5_metrics = top5_metrics_obj.result()\n","    top10_metrics = top10_metrics_obj.result()\n","\n","    print('\\r', \n","        round(test_total_loss.numpy(), 4),\n","        round(top1_metrics.numpy(), 4),\n","        round(top3_metrics.numpy(), 4),\n","        round(top5_metrics.numpy(), 4),\n","        round(top10_metrics.numpy(), 4),\n","        round((10*top1_metrics.numpy()+\n","          5*top3_metrics.numpy()+\n","          3*top5_metrics.numpy()+\n","          1*top10_metrics.numpy())/19, 4),\n","        round(endtime-starttime, 4),\n","        len(test_image_path_list),\n","        round(len(test_image_path_list)/(endtime-starttime), 4),\n","        )"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1655531331264}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}